{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Machine Learning\n",
    "Special Topics\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Understand the use of the `PolynomialFeatures()` method\n",
    "* Explore the use of Pipelines to create a workflow of transforms with a final estimator\n",
    "* Use PolynomialFeatures in a Pipeline to explore under- and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: PolynomialFeatures\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PolynomialFeatures\n",
    "\n",
    "The PolynomialFeature class has a `.fit_transform()` method that transforms input values into a series of output values. These values are often used as inputs in other models.\n",
    "\n",
    "PolynomialFeatures generates a new feature matrix that has all polynomial combinations of the original features with a degree less than or equal to the specified degree. \n",
    "\n",
    "As an example: \n",
    "\n",
    "An input sample has two dimensions (i.e. $[a, b]$) the resulting degree-2 polynomial features will be $[1, a, b, a^2, ab, b^2]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with some standard imports:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the initial `1`. If you don't want to have the leading `1`, that can be *turned off* by using the `include_bias=False` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a three element matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(3).reshape(3, 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest PolynomialFeatures is simply to return the original array, but notice that in this case, the function returns a column of `1`s as well as the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(1)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields $1, a$ for each element in the X matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have a features matrix that doesn't include the column of `1`s, you can avoid it by using the `include_bias=False` argument.\n",
    "\n",
    "Including a bias column acts as an intercept term in a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(1, include_bias=False)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields $1, a, a^2$ for each element in the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(4)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields $1, a, a^2, a^3, a^4$ for each element in the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.arange(6).reshape(3, 2)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(1)\n",
    "poly.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields $1, a, b$ for each element in the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields $1, a, b, a^2, ab, b^2$ for each element in the X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "poly.fit_transform(X2)\n",
    "\n",
    "#         1     a     b     a^2   ab   b^2   a^3  a^2*b a*b^2 b^3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yields $1, a, b, a^2, ab, b^2, a^3, a^2b, ab^2, b^3$ for each element in the X matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus for any degree that we feed into the PolynomialFeature model, we can transform an input matrix into a higher order matrix that may allow for potentially more precise calculations of `y` values, given values of `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this matter?... if you recall from your math days it is possible to create very sophisticated curves using formulas such as this:\n",
    "\n",
    "$$\n",
    "y = mx + b   \\\\\n",
    "y = ax^2 + bx + c \\\\\n",
    "y = ax^3 + bx^2 + cx + d \\\\\n",
    "y = ax^4 + bx^3 + cx^2 + dx + e \\\\\n",
    "$$\n",
    "\n",
    "With every additional argument and with the appropriate slopes, you have the ability to match a wide array of datasets.\n",
    "\n",
    "PolynomialFeatures helps you to generate matrices with multiple degrees so that you can run them through models like the LinearRegression model to identify the coefficients and intercept values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we will turn our attention to a new topic, **Pipelines**, but will come back to PolynomialFeatures momentarily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Pipelines\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, it might be necessary to transform the data in some way before feeding it into a particular machine learning model.\n",
    "\n",
    "The data may need to be scaled, changed into another format, etc.\n",
    "\n",
    "In the example we just looked at, we used a PolynomialFeatures function to generate a higher degree matrix.\n",
    "\n",
    "Pipelines allow you to feed inputs into one \"end\" of a series of components and get transformations or predictions out the other end, without having to take the output of one model and manually drop into the inputs of the next model.\n",
    "\n",
    "The following example uses the PolynomialFeatures model to transform inputs from a degree 1 polynomial into higher degree polynomials. It then takes the results of those transformations and then feeds them into the LinearRegression model. \n",
    "\n",
    "The Pipeline simplifies things so that we only have to call `.fit()` once on the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first trivial example..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data\n",
    "\n",
    "Start with some standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../universal_datasets/skincancer.txt',\n",
    "                 delim_whitespace=True,\n",
    "                 header=0,\n",
    "                 names=['state', 'lat', 'mort', 'ocean', 'long'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lat'].to_frame()\n",
    "y = df['mort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.title(\"Mortality vs Latitude\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Number of deaths\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: for this example, we are simply gonna regurgitate the input data rather than change the degree, we will use a `degree=1`. In a moment, we will look at tweaking the degree to explore underfitting and overfitting. In this first example, I merely want to focus on putting the Pipeline together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=1,\n",
    "                                         include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the magic comes into play. By providing as an argument to the Pipeline a list containing a series of tuples, we can establish which models to call and in what order.\n",
    "\n",
    "Each tuple is a step in the pipeline.\n",
    "Each tuple is comprised of a name for that step and the function or model to call during that step.\n",
    "\n",
    "Every step, except for the last step must have either a `.transform()` OR `.fit_transform()` method. As we have seen, PolynomialFeatures does indeed have a `.fit_transform()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"poly_f\", polynomial_features),\n",
    "                     (\"linear_r\", linear_regression)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: in the next cell, we simply call `.fit()` on the Pipeline. We don't have to call the `fit_transform()` method on the PolynomialFeatures at all, the Pipeline does it automagically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model has been fit, we simply call `.predict()`, like normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, let's take a quick look via a chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test, y_test, label=\"Model\")\n",
    "plt.scatter(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of under/overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a sense for how we can use a Pipeline, we are gonna create one and use it to explore the phenomena of **Underfitting** and **Overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A risk in machine learning is using a model that doesn't match the data well enough (**underfitting**) OR matches the training data so well, that it doesn't apply well to test data, it only applies to the training data (**overfitting**).\n",
    "\n",
    "For this example, we will look at three graphs. This example comes from the Scikit Learn [Underfitting/Overfitting documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html), with various degrees of modification by me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do this process three times using `degree=` of `1`, `4`, and `15` to demonstrate underfitting, a good fit, and overfitting.\n",
    "\n",
    "Two of these cases will generate linear regressions that are not straight lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, they create a function (`true_fun`) that generates a series of points on a graph in the shape of a Cosine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 30 random values as `X` inputs, they use the function to generate 30 related `y` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "x = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(x) + np.random.randn(n_samples) * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[:, np.newaxis]\n",
    "\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.title(\"Cosine Dots\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.linspace(0.05, 1, 100)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's:\n",
    "* start with PolynomialFeatures **degree of 1**\n",
    "* use the default values for LinearRegression\n",
    "* feed each into our Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=1,\n",
    "                                         include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have to call `.fit()` on the pipeline, not on each of the components in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test, y_test, label=\"Model\")\n",
    "plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "\n",
    "plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "plt.legend()\n",
    "plt.title(\"Underfit\");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the process to generate polynomial features of **degree 4**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=4,\n",
    "                                         include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test, y_test, label=\"Model\")\n",
    "plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "plt.legend()\n",
    "plt.title(\"Good match\");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's generate polynomial features of **degree 15**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=15,\n",
    "                                         include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test, y_test, label=\"Model\")\n",
    "plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "plt.legend()\n",
    "plt.title(\"Overfit\");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchas\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "The Pipeline class accepts any number of models as input and creates a sequence of steps.\n",
    "\n",
    "All models except the last must have some form of `*transform()` method that will output an appropriate matrix to feed into the next model in the pipeline.\n",
    "\n",
    "Once a pipeline is created, the user only needs to call the `.fit()` and `predict()` methods once on the pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Pipeline, we first instantiate any of the models we want to use, just as if we were creating standalone models.\n",
    "\n",
    "> ```python\n",
    "polynomial_features = PolynomialFeatures(degree=15,\n",
    "                                         include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "```\n",
    "\n",
    "Next we provide a `list` of `tuples` to the Pipeline class, where each tuple contains a key, value pair where the key is a name we want to call the step of the pipeline and the value is the model we want to use at that step:\n",
    "\n",
    "> ```python\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "```\n",
    "\n",
    "With a Pipeline in hand, we simply call `.fit()` just as we would for any model.\n",
    "\n",
    "> ```python\n",
    "pipeline.fit(X[:, np.newaxis], y)\n",
    "```\n",
    "\n",
    "Jupyter will output the Pipeline parameters for us and we can see each of the steps we defined in the correct order and we can see that each step includes the hyperparameters that we provided.\n",
    "\n",
    "> ```python\n",
    "Pipeline(memory=None,\n",
    "     steps=[('polynomial_features', PolynomialFeatures(degree=15,\n",
    "             include_bias=False, interaction_only=False)), \n",
    "            ('linear_regression', LinearRegression(copy_X=True,\n",
    "             fit_intercept=True, n_jobs=None,\n",
    "             normalize=False))])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchas\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to learn more: tips and hints\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# delete_this_line: task 01\n",
    "\n",
    "In **`jupyter`** create a simple script to complete the following tasks:\n",
    "\n",
    "\n",
    "**REPLACE THE FOLLOWING**\n",
    "\n",
    "Create a function called `me()` that prints out 3 things:\n",
    "\n",
    "* Your name\n",
    "* Your favorite food\n",
    "* Your favorite color\n",
    "\n",
    "Lastly, call the function, so that it executes when the script is run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When you complete this exercise, please put your **green** post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# delete_this_line: task 02\n",
    "\n",
    "In **`jupyter`** create a simple script to complete the following tasks:\n",
    "\n",
    "**REPLACE THE FOLLOWING**\n",
    "\n",
    "Task | Sample Object(s)\n",
    ":---|:---\n",
    "Compare two items using `and` | 'Bruce', 0\n",
    "Compare two items using `or` | '', 42\n",
    "Use the `not` operator to make an object False | 'Selina' \n",
    "Compare two numbers using comparison operators | `>, <, >=, !=, ==`\n",
    "Create a more complex/nested comparison using parenthesis and Boolean operators| `('kara' _ 'clark') _ (0 _ 0.0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When you complete this exercise, please put your **green** post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete_this_line: sample 03\n",
    "\n",
    "In your **text editor** create a simple script called:\n",
    "\n",
    "```bash\n",
    "my_lessonname_03.py```\n",
    "\n",
    "Execute your script on the command line using **`ipython`** via this command:\n",
    "\n",
    "```bash\n",
    "ipython -i my_lessonname_03.py```\n",
    "\n",
    "**REPLACE THE FOLLOWING**\n",
    "\n",
    "I suggest that as you add each feature to your script that you run it right away to test it incrementally. \n",
    "\n",
    "1. Create a variable with your first name as a string AND save it with the label: `myfname`.\n",
    "1. Create a variable with your age as an integer AND save it with the label: `myage`.\n",
    "\n",
    "1. Use `input()` to prompt for your first name AND save it with the label: `fname`.\n",
    "1. Create an `if` statement to test whether `fname` is equivalent to `myfname`. \n",
    "1. In the `if` code block: \n",
    "   1. Use `input()` prompt for your age AND save it with the label: `age` \n",
    "   1. NOTE: don't forget to convert the value to an integer.\n",
    "   1. Create a nested `if` statement to test whether `myage` and `age` are equivalent.\n",
    "1. If both tests pass, have the script print: `Your identity has been verified`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you complete this exercise, please put your **green** post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are references that may assist you in learning more:\n",
    "    \n",
    "|Title (link)|Comments|\n",
    "|---|---|\n",
    "|[General API Reference](https://scikit-learn.org/stable/modules/classes.html)||\n",
    "|[XX API Reference]()||\n",
    "|[User Guide]()||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
