{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Machine Learning\n",
    "Support Vector Machines\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Cover an overview of Support Vector Machines\n",
    "* Examine code samples that walk us through **The Process™**:\n",
    "   * Prep the data\n",
    "   * Choose the model\n",
    "   * Choose appropriate hyperparameters\n",
    "   * Fit the model\n",
    "   * Apply the model\n",
    "   * Examine the results\n",
    "* Explore a deep dive into this model\n",
    "* Review some gotchas that might complicate things\n",
    "* Review tips related to learning more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Support Vector Machines\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) are popular machine learning models because they:\n",
    "* can be used in both classification and regression\n",
    "* can be used for 2-dimensional (2D) data as well as multi-dimensional data (3D, 4D, and more)\n",
    "    * 2D -> uses a line/curve to separate the classes\n",
    "    * 3D-plus -> uses a manifold/surface to separate the classes\n",
    "* can be fairly easy to interpret, especially in 2D\n",
    "\n",
    "If I give you data points separated into two very distinct classes (or categories), we would probably find it pretty easy to draw a line between the two data points.\n",
    "\n",
    "<img src='two_classes.png' width='400'>\n",
    "\n",
    "But how do we know what is the **best line** to draw between the data points **for the purpose of labeling future data points**? The slope of the line could vary widely.\n",
    "\n",
    "SVM takes the idea of drawing a simple line between two classes of data and adds a parallel margin to either side of the line where the margins go up to the nearest point in each class. By maximizing the margin between the closest points in each class, we can select an optimal separating line. Thus SVMs qualify as `maximum margin` estimators.\n",
    "\n",
    "From there, classifying new data is simply a matter of identifying which side of the line the point is on. SVM is a form of `discriminative` classification.\n",
    "\n",
    "For this example, we will use the Support Vector Classifier (SVC). The sklearn.svm module has a number of classifiers and regression models.\n",
    "\n",
    "* SVC\n",
    "* SVR\n",
    "* LinearSVC\n",
    "* LinearSVR\n",
    "* NuSVC\n",
    "* NuSVR\n",
    "\n",
    "With this background, let's apply **The Process™** on a Support Vector Machine model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a set of standard imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# NOTE: during the Choose the Model step, we will import the \n",
    "#     model we want, but there is no reason you can't import it here.\n",
    "# from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is simply a sequence of `x` and `y` vectors to plot on a chart with a `category` assigned to each vector.\n",
    "\n",
    "The each group is identified with a category of either `1` or a `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../universal_datasets/svm_train.csv', \n",
    "                 names=['x', 'y', 'category'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(df)\n",
    "X_train = df[['x', 'y']]\n",
    "y_train = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be really useful to take a look at the `features` matrix and `target` array of the training data. \n",
    "\n",
    "* In the raw form\n",
    "* In a visualization tool\n",
    "\n",
    "For this dataset, let's use a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"A Gulf Between Red and Blue Dots\")\n",
    "\n",
    "plt.scatter(X_train['x'], X_train['y'], c=y_train,\n",
    "            cmap='seismic');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data is a similar set of vectors (x, y points) but there are no category labels/classifications.\n",
    "\n",
    "In the following plot, we chose to set the alpha channel for the dots at 0.15 which makes the dots largely transparent, so that they are visually distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../universal_datasets/svm_test.csv',\n",
    "                     names=['x', 'y'])\n",
    "\n",
    "X_test = df_test[['x', 'y']]\n",
    "\n",
    "plt.scatter(X_test['x'], X_test['y'], alpha=0.15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have already decided upon using the Support Vector Classification (SVC) model, so importing it is straightforward. But if we aren't sure what model we want we can always refer back to the [API Reference](https://scikit-learn.org/stable/modules/classes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose to assign two hyperparameters: `gamma` and `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC(gamma='scale', C=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of hyperparameters, which potentially makes this model a bit more complicated to use well. Later, we will talk about `gamma`, `kernel` and `C` and leave the rest of the parameters for the student to explore.\n",
    "\n",
    "```python\n",
    "SVC(\n",
    "    C=1.0,\n",
    "    kernel='rbf',\n",
    "    degree=3,\n",
    "    gamma='auto_deprecated',\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=False,\n",
    "    tol=0.001,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape='ovr',\n",
    "    random_state=None,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "model.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the indices of the support vectors\n",
    "model.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to confirm these indices match up to the \n",
    "#     input data... \n",
    "\n",
    "X_train.loc[[12, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the number of support vectors for each class\n",
    "model.n_support_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train['x'], X_train['y'], c=y_train,\n",
    "            cmap='seismic');\n",
    "\n",
    "plt.scatter(X_test['x'], X_test['y'], c=y_pred,\n",
    "            cmap='seismic', alpha=0.15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchas\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training data that is not easy to separate, we can project the data onto another dimension and potentially more easily separate the points.\n",
    "\n",
    "An example of this is using the `Radial Basis Function (rbf)` (more about `rbf` below) and what is called the **kernel trick**. The kernel trick can automate the projection process to enable SVC to do this projection without having to build a full-blown N-dimensional representation of the data. It basically turns a fast linear method into a fast non-linear method.\n",
    "\n",
    "Points that are farther from the support vectors do not modify the model. We say that the model is insenstive to the exact behavior of distant points.\n",
    "\n",
    "NOTE: the Huber model puts weights on outliers to suppress sensitivity to those outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kernel**\n",
    "\n",
    "Kernels are intended to take data as input and transform it into a required output form. One of the most commonly used kernels is based on the `Radial Basis Function (rbf)`, which uses squared Euclidean distance to return a value between zero and one to indicate distance between two points in the vector space around a center point.\n",
    "\n",
    "$$K(\\mathbf{x}, \\mathbf{x'}) = \\exp(-\\gamma\\|\\mathbf{x} - \\mathbf{x'}\\|^2)$$\n",
    "\n",
    "```python\n",
    "kernel : string, optional (default='rbf')\n",
    "    Specifies the kernel type to be used in the algorithm.\n",
    "    It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
    "    a callable.\n",
    "    If none is given, 'rbf' will be used. If a callable is given it is\n",
    "    used to pre-compute the kernel matrix from data matrices; that matrix\n",
    "    should be an array of shape ``(n_samples, n_samples)``.\n",
    "```\n",
    "\n",
    "**gamma**\n",
    "\n",
    "Gamma is coefficient that impacts the functioning of the kernel. When talking about the `rbf` kernel, gamma represents this. Sigma, according to the documentation on Wikipedia is a free parameter.\n",
    "\n",
    "$$\\gamma = \\tfrac{1}{2\\sigma^2}$$\n",
    "\n",
    "\n",
    "```python\n",
    "gamma : float, optional (default='auto')\n",
    "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
    "\n",
    "    Current default is 'auto' which uses 1 / n_features,\n",
    "    if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.var())\n",
    "    as value of gamma. The current default of gamma, 'auto', will change\n",
    "    to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
    "    'auto' is used as a default indicating that no explicit value of gamma\n",
    "    was passed.\n",
    "```\n",
    "\n",
    "**C**\n",
    "\n",
    "C is used by the model to determine how **hard** the margins should be. If the value of `C` is very small, then the model will allow for some overlap in the margin. If the value of `C` is very high, then the model will find only lines and margins with little OR no overlap with data points. Using a low `C` value should be tuned using model validation techniques.\n",
    "\n",
    "```python\n",
    "C : float, optional (default=1.0)\n",
    "    Penalty parameter C of the error term.\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to learn more: tips and hints\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key component to learning more about machine learning (or any technical topic, really) is exercising curiousity.\n",
    "\n",
    "As I first started looking at SVM, a couple of questions popped up right away:\n",
    "\n",
    "* What is a `kernel`?\n",
    "* What do they do?\n",
    "* What is `C`?\n",
    "* How sensitive is SVM to various values of `C`?\n",
    "* How sensitive is SVM to using different values of `gamma`\n",
    "\n",
    "I can't say I have great answers to all of these questions, yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Read the docs: task 01\n",
    "\n",
    "\n",
    "\n",
    "Take a look at the documentation for the [**k-Means Clustering (link)**](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) algorithm:\n",
    "\n",
    "Try to answer these questions:\n",
    "\n",
    "* How many times will the k-means algorithm be run with different centroid seeds if using the default setting?\n",
    "* k-means defaults to how many clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When you complete this exercise, please put your **green** post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are references that may assist you in learning more:\n",
    "    \n",
    "|Title (link)|Comments|\n",
    "|---|---|\n",
    "|[General API Reference](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)||\n",
    "|[SVM API Reference](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)||\n",
    "|[User Guide](https://scikit-learn.org/stable/modules/svm.html#svm-classification)||\n",
    "\n",
    "https://en.wikipedia.org/wiki/Radial_basis_function_kernel\n",
    "\n",
    "https://en.wikipedia.org/wiki/Radial_basis_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
