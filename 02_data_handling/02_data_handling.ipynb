{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Machine Learning\n",
    "Data handling and visualization\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Explore the datatypes that scikit-learn uses\n",
    "* Explore several techniques to prep data for use in scikit-learn\n",
    "* Examine techniques to manipulate OR review the data\n",
    "* Consider several techniques to view the data using matplotlib\n",
    "\n",
    "**NOTE**: this is not intended to be an exhaustive overview of data handling OR visualization. We intend to cover just enough to help you understand what format your data should be in, several techniques to get data into that format and then several techniques to plot data on a chart...\n",
    "\n",
    "...with the intent that we want to spend more time on the machine learning aspects of this tutorial.\n",
    "\n",
    "As we look at the various machine learning examples in later sections, we will use one or more of the techniques displayed below to get or shape the data we need for that specific algorithm/model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Data Handling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, scikit-learn uses several of the most popular datatypes found in the Python data science ecosystem:\n",
    "\n",
    "* numpy arrays\n",
    "* scipy sparse matrixes\n",
    "* pandas DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a scikit-learn classifier, all you need is a `2D array` (often called a ` features matrix` and typically labeled `X`) for the input variables and a `1D array` (often called a `target array` and typically labeled `y`) for the target labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "The 2D array `X` holds the features of your dataset as columns and holds individual samples of the data as rows.\n",
    "\n",
    "Each **column** is a separate feature. In the examples below a feature could be the price of a soda OR could be the lengths of specific beetle body parts.\n",
    "\n",
    "Each **row** in the examples below is a specific example of a soda OR a beetle.\n",
    "\n",
    "### Features example one: Soda sizes\n",
    "\n",
    "|Soda size (oz)|\n",
    "|:---|\n",
    "|12|\n",
    "|16|\n",
    "|20|\n",
    "|24|\n",
    "\n",
    "### Features example two: Beetle dimensions\n",
    "\n",
    "|Head (mm)|Thorax (mm)|Abdomen (mm)| \n",
    "|:---|:---|:---|\n",
    "|4|6|6|\n",
    "|6|10|9|\n",
    "|4|6|7|\n",
    "|7|11|9|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets\n",
    "\n",
    "The 1D array `y` holds specific target values OR categorization labels.\n",
    "\n",
    "In the examples below a target value could be the price of a specific soda OR could be the category of beetle that has body parts with specific lengths.\n",
    "\n",
    "### Target example one: Soda prices\n",
    "\n",
    "In this 1D target array, there are as many prices as there were rows in the 2D features array.\n",
    "\n",
    "```\n",
    "[0.50, 0.65, 0.70, 0.80]\n",
    "```\n",
    "\n",
    "### Target example two: Beetle classification\n",
    "\n",
    "In this 1D target array, there are as many beetle categorizations as there were rows in the 2D features array.\n",
    "\n",
    "* 0 = checkered beetle\n",
    "* 1 = diving beetle\n",
    "\n",
    "```\n",
    "[0, 1, 0, 1] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating arrays for use in scikit-learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to create `2D` and `1D` arrays. Here we will show you several quick examples from `numpy` and `pandas` that you will see in this tutorial and/or in examples in books/online.\n",
    "\n",
    "We will not dive deeply into the details... we leave it up to (in fact, we strongly encourage) the student to explore tools like `numpy`, `scipy`, and `pandas` to better understand what is happening under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([12, 16, 20, 14, 18])             # coffee sizes\n",
    "y = np.array([2.95, 3.65, 4.15, 3.25, 4.20])   # coffee prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that the features matrix must be in a 2D format and the target array must be in a 1D format, so let's look at the current arrangement using the `.shape` attribute associated with numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, both of these are simply 1D arrays of length **five**, thus the tuple only has a single dimension of 5. The comma is required because the data type produced by the `.shape` attribute is a `tuple`.\n",
    "\n",
    "To convert the `x` array from a 1D array to a 2D array, there are several techniques you will often see:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy technique one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy_one = x[:, np.newaxis]        # np.newaxis increases dimensionality\n",
    "X_numpy_one                           #     by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy_one.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy technique two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy_two = x[:, None]              # np.newaxis is actually an alias for\n",
    "X_numpy_two                           #     None, so None also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy_two.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy technique three:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy_three = x.reshape(len(x), 1)\n",
    "X_numpy_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D numpy data:\n",
    "\n",
    "If the data is already a 2D array/matrix you don't need to do anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_beetle = np.array([[4, 6, 6], \n",
    "                     [6, 10, 9], \n",
    "                     [4, 6, 7],\n",
    "                     [7, 11, 9]])\n",
    "X_beetle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_beetle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_pandas = pd.Series([12, 16, 20, 14, 18])\n",
    "y_pandas = pd.Series([2.95, 3.65, 4.15, 3.25, 4.20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might presume that a pandas Series is a 2D array, but that is not the case... as we will see when we look at the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pandas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is simply a 1D array of length **five**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas technique one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the x_pandas 1D array to a 2D array, we can convert the pandas Series to a DataFrame and we provide a name ('size'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_one = x_pandas.to_frame('size')\n",
    "X_pandas_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_one.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar/related technique if you are simply taking an existing named column (i.e. 'size') from a DataFrame is to do the following. Here, since the column/Series already has a name, we don't need to supply one as an argument to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[12, 2.95],\n",
    "                   [16, 3.65],\n",
    "                   [20, 4.15],\n",
    "                   [14, 3.25],\n",
    "                   [18, 4.20]], columns=['size', 'cost'])\n",
    "\n",
    "X_pandas_one_a = df['size'].to_frame()\n",
    "X_pandas_one_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_one_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas technique two:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the x_pandas 1D array to a 2D array, we can also use the DataFrame factory function to convert the pandas Series to a DataFrame, by giving the DataFrame constructor the name to use for the final column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_two = pd.DataFrame(x_pandas, columns=['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_two.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the raw data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see just the first few rows of a numpy array, it is common to take a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy_one[:3]       # first three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see just the first few rows of a `pandas` `Series` or `DataFrame`, it is common to use `.head()` OR to take a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_one.head(3)   # first three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pandas_one[:3]       # first three rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is fairly common to name the features of the model some variation of: `X` (as a capital letter). It is also common to differentiate between data used to train the model and data used to test the model/predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you explore machine learning, you will encounter a wide array of names for the various types of data:\n",
    "\n",
    "**Features**:\n",
    "\n",
    "* This data is what we know and is potentially (but not always) related to the target\n",
    "* Also referred to as: \n",
    "    * independent variables, observed variables, explanatory variables and input variables\n",
    "    * `x`, `X`\n",
    "    \n",
    "**Targets**:\n",
    "\n",
    "* Also referred to as: dependent variable, unobserved variable, explained variable, output variable, outcome measurement\n",
    "* Many variants are popular with statisticians, etc\n",
    "    * y, Y\n",
    "    \n",
    "**Training vs. Testing**\n",
    "\n",
    "Data will often be referred to as training data or test data. More on this in the next section.\n",
    "\n",
    "We will try to settle in on one OR two conventions and try to stick with them. But just be aware: **YMMV**, everyone has their own naming convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `sklearn.model_selection.train_test_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important component of machine learning is testing the models for some level of accuracy. It is customary to break the data into two OR more portions:\n",
    "\n",
    "|Set|Purpose|\n",
    "|:----|:----|\n",
    "|Training|Used to train the model|\n",
    "|Validation|Used to validate the model|\n",
    "|Test|Used to test the results of the validated training|\n",
    "\n",
    "For this discussion, we are gonna focus on using just two sets: **Training** and **Test**. We will leave it up to the student to explore the nuances associated with validation.\n",
    "\n",
    "To simplify the process of generating **training data** and **testing data**, scikit-learn's `model_selection` module has a function called `train_test_split()`, that can automagically break data into segments. \n",
    "\n",
    "By default, `train_test_split()` will randomize the data so that the data is well-mixed between the training sets and testing sets. This is particularly important when considering data that might be already clumped together in some artificial way (i.e. if we were to have pre-sorted all the soda price data so that small cup sizes were at the beginning of the data and large cup sizes were at the end of the data). \n",
    "\n",
    "We start by importing from `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will read a slightly larger coffee data set in from a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../universal_datasets/coffee.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we call the `.to_frame()` method on the pandas `Series` `df['size']` to create a 2D features matrix: `X`. Since the `Series` already has a column name, we don't need to provide a one as an argument in the `to_frame()` method.\n",
    "\n",
    "We can simply assign an alias `y` to the `Series` `df['price']` to because `Series` already qualify as arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['size'].to_frame()\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling the `train_test_split()` method, there are arguments to help determine the ratio between the training data and the test data, using `test_size` (generally a value between `0.0` and `1.0`, but other options are allowed). There is also a mechanism to set the random seed, using `random_state` (so that the exact split can be reproduced by collaborators, peer reviewers, students, colleagues, etc.\n",
    "\n",
    "In this case, we set the `test_size` to be `0.33` so that about a third of the records are held off as a test set.\n",
    "\n",
    "We also arbitrarily chose a `random_state` seed value of `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at each of these dataset partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to manually looking at each item, is to run it through a simple for loop to help get a sense of what the `train_test_split()` method has produced. As you grow more comfortable with tools such as `train_test_split()` you won't need to do this. \n",
    "\n",
    "But it is very useful, in the beginning, to really take a look at everything you can and start to make mental models of:\n",
    "\n",
    "* what new objects look like, \n",
    "* what data is associated with them, \n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in X_train, X_test, y_train, y_test:\n",
    "    print(item[:2])        # Let's look at just two samples\n",
    "    print('Shape:', item.shape)      # Let's confirm the number of samples\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to identifying a ratio for the `test_size` argument is to simply identify how many records to hold out.\n",
    "\n",
    "Let's redo the split, but change the `random_state` to 13 and change the `test_size` to only hold out 3 records for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=3, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in X_train, X_test, y_train, y_test:\n",
    "    print(item[:3])        # Let's look at just two samples\n",
    "    print('Shape:', item.shape)      # Let's confirm the number of samples\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, when we held out test records using a `random_state=42` argument, we got the records below.\n",
    "\n",
    "```\n",
    "Original X_test (5 records) with random_state=42 and test_size=0.33:\n",
    "\n",
    "9     18\n",
    "11    16\n",
    "0     12\n",
    "13    14\n",
    "5     12\n",
    "```\n",
    "\n",
    "Notice that not only did we successfully hold out a different number of records, but we also held out different records. Only one sample of the new test set (sample # 11) matches any of the records from the earlier test set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Data Visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, it is not enough to simply look at the data, we often want to plot the data to see relationships.\n",
    "\n",
    "By and large, we will use tools in `matplotlib` to generate charts. Again, we won't be covering this in depth, we intend to provide several simple examples of the most common types of charts we will use in later lessons so that during our examinations of the machine learning models, we can focus on the models and not the mechanics of making pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our most common chart will be the scatter plot, which can be generated in the following ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a standard import from `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna read in some sample data. For now, don't worry about the data, just recognize that it is two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../universal_datasets/linreg_train.csv',\n",
    "                     names=['x', 'y'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots generally require two sequences of values to create a series of dots. Let's create two sequences using a technique that we learned above. Plots can handle 2D matrices, so let's go ahead and shape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['x'].to_frame()\n",
    "y_train = df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three things of importance in the next cell:\n",
    "\n",
    "* Calling `plt.scatter(<x values>, <y_values>)` will generate a simple scatter plot.\n",
    "* We can always add some additional characteristics to the plot by supplying values via specific method calls, such as `.title()`\n",
    "* Appending a **semicolon** at the end of the last command, you can suppress the display of extraneous text and display nothing but the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.title(\"Dots in a box\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, our machine learning algorithms will result in assigning a label OR category to each of the points on the plot and we frequently represent the labels using colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's presume that we know the labels for the points in this graph and have the labels stored in a 1D array (in this case a numpy array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a scatter plot much like before, but we can use the `c` argument to assign labels (categories) to each element of the plot AND we can use a color map (i.e. a `cmap` such as `RdBu` OR `seismic`) to assign specific colors to each category.\n",
    "\n",
    "In this case, we have 25 points, 25 labels (one per point) and we have the `RdBu` color mapping to map a color to each category (1 OR 0) on a spectrum of red and blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train,\n",
    "            c=labels,\n",
    "            cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple `cmap`s. Each has specific characteristics. The following is the `seismic` color map, which we will commonly use in this tutorial.\n",
    "\n",
    "For details on the various colormaps or palettes available, see [**matplotlib colormaps**](https://matplotlib.org/users/colormaps.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train,\n",
    "            c=labels,\n",
    "            cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are references that may assist you in learning more:\n",
    "    \n",
    "|Title (link)|Comments|\n",
    "|---|---|\n",
    "|[General API Reference](https://scikit-learn.org/stable/modules/classes.html)||\n",
    "|[Train_Test_Split API Reference]()||\n",
    "|[Cross Validation User Guide]()||\n",
    "|numpy link||\n",
    "|pandas link||\n",
    "|scipy link||\n",
    "|[Matplotlib Colormaps](https://matplotlib.org/users/colormaps.html)|Assorted palettes available for use with `matplotlib`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
