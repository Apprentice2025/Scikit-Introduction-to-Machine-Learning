{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Machine Learning\n",
    "Intro to Scikit-Learn\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Explore machine learning techniques, tools and categories\n",
    "   * Supervised learning\n",
    "   * Unsupervised learning\n",
    "   * Classification\n",
    "   * Regression\n",
    "   * Clustering\n",
    "   * Dimensionality reduction\n",
    "* Review key characterisitcs of Scikit-Learn, especially the application programming interface (API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Techniques, Tools and Categories\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning falls into two main categories: **supervised learning** and **unsupervised learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning is the process of modeling the relationship between features of a dataset and targets (labels) associated with each element of that dataset. With a model in hand, it is possible to use the model to assign labels to a new dataset that doesn't have labels. The most common examples of supervised learning include: **classification** and **regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification allows you to assign **labels or categories** to new input data.\n",
    "\n",
    "|Inputs|Classification|\n",
    "|:---|:---|\n",
    "|Texts, emails, or comments|Spam detection|\n",
    "|Flowers, insects, or animals|Species detection|\n",
    "|Viewers, readers, buyers|Customer detection|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression analysis allows you to predict **continuous quantities** based on new input data. \n",
    "\n",
    "|Inputs|Outputs|\n",
    "|:---|:---|\n",
    "|Auto characteristics (color, model, age, etc)|Price|\n",
    "|Advertising dollars spent|Sales revenue|\n",
    "|Candidate characteristics|Salary|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning is the process of modeling relationships amongst features of a dataset in a way that classifies the raw data without supplying any input labels. There are many algorithms that enable relationships to be identified and each of these models seek to replicate human logic in finding patterns in data. Two of the most common unsupervised learning approaches are **clustering** and **dimensionality reduction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster analysis or clustering is a technique for grouping a collection of objects so that all the objects in a single cluster are more similar to each other than to objects in other clusters.\n",
    "\n",
    "|Inputs|Classification|\n",
    "|:---|:---|\n",
    "|Images|Grouping/categorization|\n",
    "|Marketing data|Customer segmentation|\n",
    "|Social network data|Community classification|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction (also dimension reduction) is the process of reducing the number of random variables in a dataset by identify a set of principal variables. Dimensionality reduction can be used for feature selection or feature extraction.\n",
    "\n",
    "In some cases, data analysis such as regression or classification can be done in the reduced space more easily and/or accurately than in the original space.\n",
    "\n",
    "Some benefits from using dimensionality reduction include:\n",
    "\n",
    "* It reduces the computation time and storage space requirements\n",
    "* It can enable data visualization if the dimensions can be reduced to 2D/3D\n",
    "* It can improve the interpretation of the parameters of a machine learning model\n",
    "* It helps to avoid issues related to increase in data sparsity as data volume increases ([curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Characteristics of Scikit-Learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn is a well known package that provides access to many common machine learning algorithms through a consistent, well-organized Application Programming Interface (API) and is supported by very thorough and comprehensive documentation.\n",
    "\n",
    "The uniform syntax and the consistency in how the API is designed means that once you learn one model, it is surprisingly easy to pick up additional models.\n",
    "\n",
    "A key goal for this workshop is to help you walk away feeling familiar with:\n",
    "\n",
    "* the API\n",
    "* some of the vocabulary of machine learning\n",
    "* how to learn more\n",
    "\n",
    "If we succeed in these goals, you will be well-poised to continue your journey and to pursue future studies in the awesomeness that is machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scikit-Learn API\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scikit-Learn interface follows a number of guidelines covered in the API Contract (as defined in the [**API design paper**](https://arxiv.org/abs/1309.0238). Quoting from that paper:\n",
    "\n",
    "\"As much as possible, our design choices have been guided so as to avoid the\n",
    "proliferation of framework code. We try to adopt simple conventions and to\n",
    "limit to a minimum the number of methods an object must implement. The API\n",
    "is designed to adhere to the following broad principles:\n",
    "\n",
    "**Consistency**. All objects (basic or composite) share a consistent interface composed of a limited set of methods. This interface is documented in a consistent manner for all objects.\n",
    "\n",
    "**Inspection**. Constructor parameters and parameter values determined by learning algorithms are stored and exposed as public attributes.\n",
    "\n",
    "**Non-proliferation of classes**. Learning algorithms are the only objects to be\n",
    "represented using custom classes. Datasets are represented as NumPy arrays\n",
    "or SciPy sparse matrices. Hyper-parameter names and values are represented\n",
    "as standard Python strings or numbers whenever possible. This keeps scikitlearn easy to use and easy to combine with other libraries.\n",
    "\n",
    "**Composition**. Many machine learning tasks are expressible as sequences or\n",
    "combinations of transformations to data. Some learning algorithms are also\n",
    "naturally viewed as meta-algorithms parametrized on other algorithms. Whenever feasible, such algorithms are implemented and composed from existing\n",
    "building blocks.\n",
    "\n",
    "**Sensible defaults**. Whenever an operation requires a user-defined parameter,\n",
    "an appropriate default value is defined by the library. The default value\n",
    "should cause the operation to be performed in a sensible way (giving a baseline solution for the task at hand).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some concrete details on how the API is put together: [Contributors API Overview](https://scikit-learn.org/stable/developers/contributing.html#api-overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Scikit-Learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By and large, using any given model in Scikit-Learn will follow a set of straightforward steps. Each of our examples will follow what I call **The Processâ„¢**.\n",
    "\n",
    "1. **Prep the data**: the data must be well prepared for it to be usable in the various models. This preparation may include normalization, cleansing, wrangling of the data. It often needs to be separated into a `features` matrix and a `target` vector (array) and/or may need to be broken into separate collections of data for training versus testing purposes.\n",
    "\n",
    "1. **Choose the model**: to choose a model, we will import the appropriate estimator class\n",
    "\n",
    "1. **Choose appropriate hyperparameters**: to prepare the model, we create a class instance and provide hyperparameters as arguments to the class\n",
    "\n",
    "1. **Fit the model**: call the `.fit()` method on the model instance and provide training data\n",
    "\n",
    "1. **Apply the model**: lastly, we apply the model to new data, using primarily one of two methods:\n",
    "\n",
    "   * **Supervised learning**: generally, we use the `.predict()` method to predict new labels\n",
    "   * **Unsupervised learning**: generally, we use either the `.predict()` or `.transform()` methods to predict properties OR transform properties of the data.\n",
    "   \n",
    "1. **Examine the results**: it is recommended that we look over the results and do a sanity check. Some of this can done by looking at output values. Other times it really helps to have some form of data visualization (graph/chart) to help us examine the model predictions or transformations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will take a quick look at coffee prices near the North Shore of Oahu, Hawaii. Our goal will be to predict the price of a cup of coffee, given a cup size.\n",
    "\n",
    "These prices come from several coffee shops in the area, in 2019.\n",
    "\n",
    "|Size (oz)|Price ($)|\n",
    "|----|----|\n",
    "|12|2.95|\n",
    "|16|3.65|\n",
    "|20|4.15|\n",
    "|14|3.25|\n",
    "|18|4.20|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking generally at the data using some charting tools and putting it into a format that our machine learning tools can use.\n",
    "\n",
    "Let's look at the data in a simple scatter plot to compare the cost of coffee versus the size of the cup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a set of standard imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# NOTE: during the Choose the Model step, we will import the \n",
    "#     model we want, but there is no reason you can't import it here.\n",
    "# from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([12, 16, 20, 14, 18])             # Coffee sizes\n",
    "y_train = np.array([2.95, 3.65, 4.15, 3.25, 4.20])   # Coffee prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be really useful to take a look at the features matrix and target array of the training data. \n",
    "\n",
    "* In the raw form\n",
    "* In a visualization tool\n",
    "\n",
    "For this dataset, let's use a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to put this data into a linear regression machine learning algorithm, our features (coffee sizes/`x_train` values) need to be in a matrix format, with one \"row\" per data point (despite the row only having a single value!). Currently, our `x_train` values are simply an array, not a matrix, so we use a tool in `numpy` to increase the number of dimensions in the data.  The following snippet slices from the first value of x to the last value and adds a new axis/new dimension.\n",
    "\n",
    "```\n",
    "x_train[:, np.newaxis]\n",
    "```\n",
    "\n",
    "It is fairly common to name the features of the model: `X_train` (as a capital letter) or to label the data as a training set. So, in this case, as we convert the data, we will also set the variable name to uppercase. **YMMV**: everyone has their own naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of x_train (note: lowercase x):', x_train.shape)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train[:, np.newaxis]                           # creates an array of arrays\n",
    "print('Shape of X_train (note: uppercase X):', X_train.shape)    # five rows, one value per row\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target values are generally labeled `y_train` (lower case) and these values can be a simple array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate some test data to see what values the model will predict.\n",
    "\n",
    "Let's prep several cup sizes to see what price the model will predict.\n",
    "\n",
    "It is common to see these data sets labeled as `fit` data OR as `test` data, hence you might see labels like (`xfit`, `Xfit`, `yfit`, `xtest`, `X_test`, `y_test`).\n",
    "\n",
    "We start by pulling together a set of `x_test` values (representing size in oz.) and storing them in a matrix for inclusion as an argument when we get to the prediction phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([16, 15, 12, 20, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test[:, None]      # None will accomplish the same\n",
    "X_test                        # outcome as np.newaxis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we are gonna import a simple **linear regression** model from the sklearn collection of linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model comes, as do most of the models in sklearn with arguments (or hyperparameters) set to sane defaults, so for this case, we won't add or change any arguments.\n",
    "\n",
    "**NOTE**: When Jupyter evaluates a model, it displays a string representation of that model with the current settings for the model, including any defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a prepared model, we need to feed it data to evaluate. For this linear regression model, we give it two arguments: `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these inputs, the model was able to calculate the **slope** (coefficient) and the **y-intercept** of the line that aligns most closely with our training data.\n",
    "\n",
    "Let's look at both of these calculated results.\n",
    "\n",
    "```python\n",
    "model.coef_\n",
    "model.intercept_\n",
    "```\n",
    "\n",
    "**NOTE**: scikit-learn appends an `_` to the end of attributes that return **calculated** values. It does this to help distinguish between inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can plot all of the data points together on one chart:\n",
    "\n",
    "* original values in purple\n",
    "* predicted values in red\n",
    "* predicted slope of the line that best fits the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, color='rebeccapurple')\n",
    "plt.scatter(x_test, y_pred, color='red')\n",
    "plt.plot(x_test, y_pred, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, against the above graph:\n",
    "\n",
    "print('Coefficient/slope:', model.coef_)\n",
    "print('y-intercept:', model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you explore machine learning, you will encounter a wide array of names for the various types of data:\n",
    "\n",
    "**Features**:\n",
    "\n",
    "* This data is what we know and is potentially (but not always) related to the target\n",
    "* Also referred to as: \n",
    "    * independent variables, observed variables, explanatory variables and input variables\n",
    "    * `x`, `X`\n",
    "    \n",
    "**Targets**:\n",
    "\n",
    "* Also referred to as: dependent variable, unobserved variable, explained variable, output variable, outcome measurement\n",
    "* Many variants are popular with statisticians, etc\n",
    "    * y, Y\n",
    "    \n",
    "**Training vs. Testing**\n",
    "\n",
    "Data may also be referred to as training data or test data. More on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When prepping your data, it is important to formulate the data into the format that the tool expects.\n",
    "\n",
    "`Features` are expected to be a matrix and bad things happen if you simply provide an array.\n",
    "\n",
    "How do you know what you have and whether it is a matrix?\n",
    "\n",
    "* `type(obj)` to determine whether you have a compatible data type\n",
    "* `obj.shape` to determine what shape the data is in (i.e. a 1D array versus a 2D matrix)\n",
    "* evaluate it in Jupyter and visually look at what you have\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to learn more: tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we explore the Scikit-Learn API, and as we progress through the upcoming examples I want to pre-position you for success by showing you where and how you can learn more.\n",
    "\n",
    "One great resource to better understand the many options available to you in terms of the machine learning algorithms and the hyper parameters in scikit learn is the API Reference.\n",
    "\n",
    "[API Reference](https://scikit-learn.org/stable/modules/classes.html): A one-stop shop for the classes and functions in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Task 01**\n",
    "\n",
    "* Open the API Reference and find the section on Gaussian Naive Bayes\n",
    "* Review that section (at a high level) for about 1.5 minutes\n",
    "* Make notes of any words that you aren't familiar with. See if you hear them later in this tutorial\n",
    "* Find the link to the User Guide section on Gaussian Naive Bayes and read that article for 1.5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When you complete this exercise, please put your **green** post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are references that may assist you in learning more:\n",
    "    \n",
    "|Title (link)|Comments|\n",
    "|---|---|\n",
    "|[API Reference](https://scikit-learn.org/stable/modules/classes.html)|One stop shop for the classes and functions in `sklearn`|\n",
    "|[Contributors API Overview](https://scikit-learn.org/stable/developers/contributing.html#api-overview)|Overview of the API for contributors to scikit learn|\n",
    "|[API design contract](https://arxiv.org/abs/1309.0238)|An overview of the philosophy behind the API design|\n",
    "|[Regression Analysis](https://en.wikipedia.org/wiki/Regression_analysis)|An article on regression analysis|\n",
    "|[Cluster analysis](https://en.wikipedia.org/wiki/Cluster_analysis)|An article on cluster analysis|\n",
    "|[curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)|An article on the curse of dimensionality|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
