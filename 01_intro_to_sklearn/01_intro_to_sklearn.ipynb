{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Machine Learning\n",
    "Intro to Scikit-Learn\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Explore machine learning techniques, tools and categories\n",
    "   * Supervised learning\n",
    "   * Unsupervised learning\n",
    "   * Classification\n",
    "   * Regression\n",
    "   * Clustering\n",
    "   * Dimensionality reduction\n",
    "* Review key characterisitcs of Scikit-Learn, especially the application programming interface (API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Techniques, Tools and Categories\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning falls into two main categories: **supervised learning** and **unsupervised learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning is the process of modeling the relationship between features of a dataset and targets (labels) associated with each sample of that dataset. With a model in hand, it is possible to use the model to either assign labels to a new dataset that doesn't yet have labels or calculate output values. The most common examples of supervised learning include: **classification** and **regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification allows you to assign discrete **labels or categories** to new input data.\n",
    "\n",
    "|Inputs|Classification|\n",
    "|:---|:---|\n",
    "|Texts, emails, or comments|Spam detection|\n",
    "|Flowers, insects, or animals|Species detection|\n",
    "|Viewers, readers, buyers|Customer detection|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression analysis allows you to predict **continuous quantities** based on new input data. \n",
    "\n",
    "|Inputs|Outputs|\n",
    "|:---|:---|\n",
    "|Auto characteristics (color, model, age, etc)|Price|\n",
    "|Advertising dollars spent|Sales revenue|\n",
    "|Candidate characteristics|Salary|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning is the process of modeling relationships amongst features of a dataset in a way that classifies the raw data without supplying any input labels. There are many algorithms that enable relationships to be identified and each of these models seek to replicate human logic in finding patterns in data. Two of the most common unsupervised learning approaches are **clustering** and **dimensionality reduction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster analysis or clustering is a technique for grouping a collection of objects so that all the objects in a single cluster are more similar to each other than to objects in other clusters.\n",
    "\n",
    "|Inputs|Classification|\n",
    "|:---|:---|\n",
    "|Images|Grouping/categorization|\n",
    "|Marketing data|Customer segmentation|\n",
    "|Social network data|Community classification|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction (also dimension reduction) is the process of reducing the number of random variables in a dataset by identifying a set of principal variables. Dimensionality reduction can be used for feature selection or feature extraction.\n",
    "\n",
    "In some cases, data analysis such as regression or classification can be done in the reduced space more easily and/or accurately than in the original space.\n",
    "\n",
    "Some benefits from using dimensionality reduction include:\n",
    "\n",
    "* It reduces the computation time and storage space requirements\n",
    "* It can enable easier data visualization if the dimensions can be reduced to much lower dimensions like 2D/3D\n",
    "* It can improve the interpretation of the parameters of a machine learning model\n",
    "* It helps to avoid issues related to increase in data sparsity as data volume increases ([curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Characteristics of Scikit-Learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn is a well known package that provides access to many common machine learning algorithms through a consistent, well-organized Application Programming Interface (API) and is supported by very thorough and comprehensive documentation.\n",
    "\n",
    "The uniform syntax and the consistency in how the API is designed means that once you learn one model, it is surprisingly easy to pick up additional models.\n",
    "\n",
    "A key goal for this workshop is for you to walk away:\n",
    "\n",
    "* understanding the API\n",
    "* with an improved knowledge of the vocabulary of machine learning\n",
    "* knowing how to learn more\n",
    "\n",
    "If we succeed in these goals, you will be well-poised to continue your journey and to pursue future studies in the awesomeness that is machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scikit-Learn API\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scikit-Learn interface follows a number of guidelines covered in the API Contract (as defined in the [**API design paper**](https://arxiv.org/abs/1309.0238)). Quoting from that paper:\n",
    "\n",
    "> As much as possible, our design choices have been guided so as to avoid the\n",
    "proliferation of framework code. We try to adopt simple conventions and to\n",
    "limit to a minimum the number of methods an object must implement. The API\n",
    "is designed to adhere to the following broad principles:\n",
    "\n",
    "> **Consistency**. All objects (basic or composite) share a consistent interface composed of a limited set of methods. This interface is documented in a consistent manner for all objects.\n",
    "\n",
    "> **Inspection**. Constructor parameters and parameter values determined by learning algorithms are stored and exposed as public attributes.\n",
    "\n",
    "> **Non-proliferation of classes**. Learning algorithms are the only objects to be\n",
    "represented using custom classes. Datasets are represented as NumPy arrays\n",
    "or SciPy sparse matrices. Hyper-parameter names and values are represented\n",
    "as standard Python strings or numbers whenever possible. This keeps scikit-learn easy to use and easy to combine with other libraries.\n",
    "\n",
    "> **Composition**. Many machine learning tasks are expressible as sequences or\n",
    "combinations of transformations to data. Some learning algorithms are also\n",
    "naturally viewed as meta-algorithms parametrized on other algorithms. Whenever feasible, such algorithms are implemented and composed from existing\n",
    "building blocks.\n",
    "\n",
    "> **Sensible defaults**. Whenever an operation requires a user-defined parameter,\n",
    "an appropriate default value is defined by the library. The default value\n",
    "should cause the operation to be performed in a sensible way (giving a baseline solution for the task at hand)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some concrete details on how the API is put together: **[Contributors API Overview](https://scikit-learn.org/stable/developers/contributing.html#api-overview)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Scikit-Learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By and large, using any given model in Scikit-Learn will follow a set of straightforward steps. Each of our examples will follow what I call **The Processâ„¢**.\n",
    "\n",
    "1. **Prep the data**: the data must be well prepared for it to be usable in the various models. This preparation may include normalization, cleansing, wrangling of the data. It often needs to be separated into a `features` matrix and a `target` vector (array) and/or may need to be broken into separate collections of data for training versus testing purposes.\n",
    "\n",
    "1. **Choose the model**: to choose a model, we will import the appropriate estimator class\n",
    "\n",
    "1. **Choose appropriate hyperparameters**: to prepare the model, we create a class instance and provide hyperparameters as arguments to the class\n",
    "\n",
    "1. **Fit the model**: to fit the model to the existing data, we call the `.fit()` method on the model instance and provide training data\n",
    "\n",
    "1. **Apply the model**: next, we apply the model to new data, primarily by calling one of two methods:\n",
    "\n",
    "   * **Supervised learning**: generally, we use the `.predict()` method to predict new labels\n",
    "   * **Unsupervised learning**: generally, we use either the `.predict()` or `.transform()` methods to predict properties OR transform properties of the data.\n",
    "   \n",
    "1. **Examine the results**: lastly, it is recommended that we look over the results and do a sanity check. Some of this can be done by simply looking at output values. Other times it really helps to have some form of data visualization (i.e. graph/chart) to help us examine the model predictions or transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To whet our appetite for what's to come, we will take a quick look at coffee prices near the North Shore of Oahu, Hawaii. Our goal will be to predict the price of a cup of coffee, given a cup size.\n",
    "\n",
    "These prices come from several coffee shops in the area, in 2019.\n",
    "\n",
    "|Size (oz)|Price ($)|\n",
    "|----|----|\n",
    "|12|2.95|\n",
    "|16|3.65|\n",
    "|20|4.15|\n",
    "|14|3.25|\n",
    "|18|4.20|\n",
    "|20|4.00|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data in a simple scatter plot to compare the cost of coffee versus the size of the cup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a set of standard imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# NOTE: during the Choose the Model step, we will import the \n",
    "#     model we want, but there is no reason you can't import it here.\n",
    "# from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The training data**:\n",
    "\n",
    "We start off by making two `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([12, 16, 20, 14, 18, 20])               # Coffee sizes\n",
    "y_train = np.array([2.95, 3.65, 4.15, 3.25, 4.20, 4.00])   # Coffee prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we plot them using a `matplotlib` scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to put this data into a linear regression machine learning algorithm, we need to create our features matrix, which includes just our coffee sizes (`x_train` values).\n",
    "\n",
    "In this case, we will use one of the `numpy` techniques to increase the dimensionality of the `x_train` array. We will discuss this process in greater detail in a few minutes.\n",
    "```\n",
    "X_train = x_train[:, np.newaxis]\n",
    "```\n",
    "\n",
    "We will call our training set: `X_train` (with an upper case `X`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train[:, np.newaxis]        # creates an array of arrays\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target values are generally labeled `y_train` (with a lower case `y`) and these values can be a simple array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, the test data**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have some test data to see what values the model will predict. Let's presume that some friends will be coming to the North Shore of Oahu and want to buy some coffee in various sizes, include some potentially unusual sizes.\n",
    "\n",
    "Based on their requests, we prep several cup sizes to see what price the model will predict.\n",
    "\n",
    "We generate a set of `x_test` values (representing size in oz.) in an array. Then we convert the array to a 2D matrix for inclusion as an argument when we get to the prediction phase. As noted above, we will discuss this in detail shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([16, 15, 12, 20, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test[:, None]      # None will accomplish the same\n",
    "X_test                        # outcome as np.newaxis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this quick example, we are gonna import a simple **linear regression** model from the sklearn collection of linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model comes, as do most of the models in sklearn with arguments (or hyperparameters) set to sane defaults, so for this case, we won't add or change any arguments.\n",
    "\n",
    "**NOTE**: When Jupyter evaluates a model, it displays a string representation of that model with the current settings for the model, including any defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a prepared model, we need to feed it data to evaluate. For this linear regression model, we give it two arguments: `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these inputs, the model was able to calculate the **slope** (coefficient) and the **y-intercept** of the line that aligns most closely with our training data.\n",
    "\n",
    "Let's look at both of these calculated results.\n",
    "\n",
    "```python\n",
    "model.coef_\n",
    "model.intercept_\n",
    "```\n",
    "\n",
    "**NOTE**: scikit-learn appends an `_` to the end of attributes that return **calculated** values. It does this to help distinguish between inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can plot all of the data points together on one chart:\n",
    "\n",
    "* original values in purple\n",
    "* predicted values in red\n",
    "* predicted slope of the line that best fits the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, color='rebeccapurple')\n",
    "plt.scatter(x_test, y_pred, color='red', alpha=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, color='rebeccapurple')\n",
    "plt.plot(x_test, y_pred, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The scikit-learn API**: The scikit-learn API is very rich and has many well-thought out approaches. The [API design contract document ](https://arxiv.org/pdf/1309.0238.pdf) helps characterize some of the philosophy behind the tool, which I found to be useful in understand how to use the tool. I probably wouldn't suggest reading the whole document right off the bat, but everything up to *Section 3 Advanced API* is a good overview of the philosophy, some aspects of data formats, and scikit-learn Estimators and Predictors.\n",
    "\n",
    "**Linear Regression**: We will revisit Linear Regression model in a later lesson and will provide more of a deep dive there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gotchas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant struggle for beginners can be ensuring that the data is in the right format. We will cover that topic in the next session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to learn more: tips and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we explore the Scikit-Learn API, and as we progress through the upcoming examples I want to pre-position you for success by showing you where and how you can learn more.\n",
    "\n",
    "One great resource to better understand the many options available to you in terms of the machine learning algorithms and the hyper parameters in scikit learn is the API Reference. Throughout the following discussions, we will revisit the API reference repeatedly.\n",
    "\n",
    "**[API Reference](https://scikit-learn.org/stable/modules/classes.html)**: A one-stop shop for the classes and functions in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Task 01**\n",
    "\n",
    "* Open the API Reference (mentioned above) and find the section on `model_selection.train_test_split`\n",
    "* Review that section (at a high level) for about 1.5 minutes looking for the following:\n",
    "   * Make notes of any words that you aren't familiar with. See if you hear them later in this tutorial\n",
    "   * Explore the section that describes what type of data the `train_test_split()` function returns. What will you get back?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When you complete this exercise, please put your **green** post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are references that may assist you in learning more:\n",
    "    \n",
    "|Title (link)|Comments|\n",
    "|---|---|\n",
    "|[API Reference](https://scikit-learn.org/stable/modules/classes.html)|One stop shop for the classes and functions in `sklearn`|\n",
    "|[Contributors API Overview](https://scikit-learn.org/stable/developers/contributing.html#api-overview)|Overview of the API for contributors to scikit learn|\n",
    "|[API design contract](https://arxiv.org/abs/1309.0238)|An overview of the philosophy behind the API design|\n",
    "|[Regression Analysis](https://en.wikipedia.org/wiki/Regression_analysis)|An article on regression analysis|\n",
    "|[Cluster analysis](https://en.wikipedia.org/wiki/Cluster_analysis)|An article on cluster analysis|\n",
    "|[curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality)|An article on the curse of dimensionality|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
