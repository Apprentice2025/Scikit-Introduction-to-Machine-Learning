{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Machine Learning\n",
    "Naive Bayes Classification\n",
    "\n",
    "<img src='../universal_images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, students should expect to:\n",
    "\n",
    "* Cover an overview of Naive Bayes Classification\n",
    "* Examine code samples that walk us through **The Processâ„¢**:\n",
    "   * Prep the data\n",
    "   * Choose the model\n",
    "   * Choose appropriate hyperparameters\n",
    "   * Fit the model\n",
    "   * Apply the model\n",
    "   * Examine the results\n",
    "* Explore a deep dive into this model\n",
    "* Review some gotchas that might complicate things\n",
    "* Review tips related to learning more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Naive Bayes Classification\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Classification models are popular machine learning models because they:\n",
    "* are fast\n",
    "* are simple with few tunable hyperparameters\n",
    "* are suitable for datasets with very high dimensions\n",
    "* can provide a nice baseline classification to start with before considering more sophisticated models\n",
    "\n",
    "<br>\n",
    "<img src='naive_bayes_ftw.png' width='600'>\n",
    "\n",
    "\n",
    "Naive Bayes Classifiers rely upon Bayes Theorem that allows you to predict the probability of a `label` if given some set of `features`:\n",
    "\n",
    "$$P(label | features)$$\n",
    "\n",
    "We won't cover the math here. ðŸ˜€\n",
    "\n",
    "I do go into it in my [**Intro to Statistics and Probability**](https://www.youtube.com/watch?v=zzbw0JbiI6Y) tutorial from Pycon 2018. Check it out!\n",
    "\n",
    "Scikit-learn has a number of Naive Bayes Classifiers. They are referred to as **naive** because they make certain presumptions about the data.\n",
    "\n",
    "Each of the following has slightly different assumptions about the data. For example, the GaussianNB model that we will look at presumes that the \"likelihood of the features is assumed to be Gaussian\" (i.e. the likelihood of any given feature falls on a bell curve).\n",
    "\n",
    "* BernoulliNB\n",
    "* ComplementNB\n",
    "* GaussianNB\n",
    "* MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through the steps of **The Processâ„¢** to see how this works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a set of standard imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# NOTE: during the Choose the Model step, we will import the \n",
    "#     model we want, but there is no reason you can't import it here.\n",
    "# from sklearn.naive_bayes import GaussianNB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the banana lovers in the room:\n",
    "# fake data warning...\n",
    "\n",
    "df = pd.read_csv('../universal_datasets/bananas.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here two columns from a `pandas DataFrame` represent a suitable 2D matrix for the `features`.\n",
    "\n",
    "One column from the `pandas DataFrame` (i.e. a `pandas Series`) is suitable as the `target` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['length', 'width']]\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be really useful to take a look at the features matrix and target array of the training data. \n",
    "\n",
    "* In the raw form\n",
    "* In a visualization tool\n",
    "\n",
    "For this dataset, let's use a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in X_train, X_test, y_train, y_test:\n",
    "    print(item[:2])        # Let's look at just two samples\n",
    "    print(item.shape)      # Let's confirm the number of samples\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train['length'], X_train['width'], c=y_train,\n",
    "            cmap='seismic')\n",
    "plt.title(\"'Cavendish' vs. 'Apple Banana' Training Data\");\n",
    "\n",
    "# NOTE TO SELF: Blue is cat zero, red is cat one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plot of the test data, we chose to set the `alpha` channel for the dots at 0.15 which makes the dots largely transparent, so that they are visually distinct. Later we will plot the training data and the test data on the same graph and that transparencey will help to segregate them visually.\n",
    "\n",
    "AND, although we know what category each of these falls into, we chose to keep them all the same color, since we want to rely upon the model to categorize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"All the test points\")\n",
    "plt.scatter(X_test['length'], X_test['width'], alpha=0.15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have already decided upon using the GaussianNB model, so importing it is straightforward. But if we aren't sure what model we want we can always refer back to the [API Reference](https://scikit-learn.org/stable/modules/classes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Appropriate Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't require any hyperparameters, so we simply call the `GaussianNB` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we supply the **features matrix** and a **target array** that we generated above. Notice that it immediately provides a summary of the hyperparameters (in this case, the defaults) that were supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now supply the test features matrix in expectation that the model will produce an array of labels (categories): one label for each sample in the features matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Red and Blue Results\")\n",
    "\n",
    "plt.scatter(X_train['length'], X_train['width'], c=y_train,\n",
    "            cmap='seismic')\n",
    "\n",
    "plt.scatter(X_test['length'], X_test['width'], c=y_pred,\n",
    "            cmap='seismic',\n",
    "            alpha=0.15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchas\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of problems arose the first time I dove into this model:\n",
    "    \n",
    "**Naming conventions**: I ran into snags with naming conventions. My data was randomly generated and I just pictured it as **x and y coordinates**. But having x values and y values on my graph (and in my head) threw everything out of whack when I tried to translate that to the `X` and `y` inputs and outputs that are commonly used in models and in statistics, etc. If my data were naturally labeled as anything else, it might have been less painful to mentally translate:\n",
    "\n",
    "|Alternate|Labels|\n",
    "|:---|:---|\n",
    "|lat|long|\n",
    "|price|quantity sold|\n",
    "|passing yards|wins|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making graphs shouldn't distract you from the machine learning**: Above, (an in most of these sessions) we have a number of dataviz steps intermixed with our machine learning steps. And there is the possibility that it might lead to confusion about what parts are *critical* to the machine learning and which parts are *nice to have*. Presuming your data is prepared properly, **these four lines** predict the category OR label for all the values in the test set. \n",
    "\n",
    "```python\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "**Sometimes starting too big is too confusing**: I often recommend that students pare back their problem to a small handful of items so that they can really see what is happening. Since this model takes a pair of coordinates and returns a label to say whether the coordinates fit in the **blue** category OR the **red** category, let's take a pair of coordinates that we know should fit clearly into the blue category (i.e. something above the dividing line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83  187.600405  36.487954     0\n",
    "\n",
    "y_pred_single = model.predict([[187, 36]])\n",
    "y_pred_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a pair of points (one in each category **red** and **blue**) and ensure that we get two different labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28  231.568879  32.733688    1\n",
    "# 93  190.142527  45.764529    0\n",
    "\n",
    "y_pred_pair = model.predict([[232, 33],\n",
    "                             [190, 46]])\n",
    "y_pred_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to learn more: tips and hints\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should you do to advance your skills?\n",
    "\n",
    "**Play with the tools**:\n",
    "\n",
    "<img src='../universal_images/changing_stuff.jpg' width='350'>\n",
    "\n",
    "**Get familiar with your favorite graphing library**: being able to visualize the results will help you get a sense of whether your model is accurately predicting. It will also help you to better succeed at the **ultimate goal of data science**:\n",
    "\n",
    "> Data science is meant to inform and thus enable action.\n",
    "\n",
    "\n",
    "**Read the docs**: yeah... I know they can be scary. Regardless, the more time you spend reading the docs, the faster you will begin to better understand the nuances of different models, which models apply in which situations. Don't be afraid if there are words in there that you don't understand. The vocabulary will come, given time and plenty of exposure. From this lesson, several good resources include:\n",
    "* [API Reference](https://scikit-learn.org/stable/modules/classes.html)\n",
    "* [Gaussian Naive Bayes Page](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "* [User Guide: Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "\n",
    "**Don't just copy-paste other people's models**: go home, find a dataset with values that are suitable to a given model and create your own model. Then put in some test values and see if it predicts properly.\n",
    "\n",
    "**Read the error messages**: They are sometimes scarier than the docs but they will often give you some insight into the nature of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Points!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Read the docs...\n",
    "\n",
    "Explore the docs related to Linear Models and Overfitting for about 3 - 4 minutes.\n",
    "\n",
    "[**Linear Models (link)**](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)\n",
    "\n",
    "Find answers to the following:\n",
    "\n",
    "* How many sample graphs do they offer up as examples?\n",
    "* What is the best possible .score() value and what is the worst possible .score() value?\n",
    "\n",
    "[**Overfitting (link)**](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html)\n",
    "\n",
    "* What technique can be used to quantitatively evaluate underfitting/overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "When you complete this exercise, please put your **green** post-it on your monitor. \n",
    "\n",
    "If you want to continue on at your own-pace, please feel free to do so.\n",
    "\n",
    "<img src='../universal_images/green_sticky.300px.png' width='200' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are references that may assist you in learning more:\n",
    "    \n",
    "|Title (link)|Comments|\n",
    "|---|---|\n",
    "|[API Reference](https://scikit-learn.org/stable/modules/classes.html)||\n",
    "|[Gaussian Naive Bayes Page](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)||\n",
    "|[User Guide: Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)||"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
